# RK3576 嵌入式 AI 开发实战计划

> 📅 起始日期：2025-12-18
> 🎯 目标：在 RK3576 上实现 K230 同等级 AI 视觉功能
> 💡 策略：**优先使用 RKNN Model Zoo 预训练模型，避免重复训练**

---

## 🎯 功能实现目标与模型来源

### ✅ 可直接使用的预训练模型（RKNN Model Zoo）

| 功能 | 推荐模型 | 来源 | 是否需要训练 |
|------|----------|------|--------------|
| **目标检测** | YOLOv5s / YOLOv8n | RKNN Model Zoo | ❌ 不需要 |
| **人脸检测** | RetinaFace | RKNN Model Zoo | ❌ 不需要 |
| **人脸识别** | ArcFace / MobileFaceNet | RKNN Model Zoo | ❌ 不需要 |
| **人体姿态** | MoveNet / PoseNet | RKNN Model Zoo | ❌ 不需要 |
| **人体分割** | PP-HumanSeg | RKNN Model Zoo | ❌ 不需要 |
| **OCR文字** | PPOCR | RKNN Model Zoo | ❌ 不需要 |
| **车牌识别** | LPRNet | RKNN Model Zoo | ❌ 不需要 |
| **图像分类** | MobileNet / ResNet | RKNN Model Zoo | ❌ 不需要 |

### ⚠️ 需要额外处理的功能

| 功能 | 解决方案 | 优先级 | 备注 |
|------|----------|--------|------|
| **安全帽检测** | YOLOv8 + 自定义训练 | ⭐⭐ | 公开数据集快速训练 |
| **二维码识别** | OpenCV / ZBar | ⭐⭐⭐ | **CPU 插件**，不混入 NPU pipeline |
| **跌倒检测** | MoveNet + 状态机 | ⭐⭐ | 连续帧+时间阈值判断 |
| **手势识别** | YOLO 手势类别 | ⭐ | 加分项，最后做 |

---

## � RKNN Model Zoo 资源

**官方仓库：** https://github.com/airockchip/rknn_model_zoo

**预训练模型下载目录结构：**
```
rknn_model_zoo/
├── models/
│   ├── CV/
│   │   ├── object_detection/
│   │   │   ├── yolov5/
│   │   │   ├── yolov8/
│   │   │   └── ...
│   │   ├── face/
│   │   │   ├── retinaface/
│   │   │   └── arcface/
│   │   ├── body/
│   │   │   ├── movenet/
│   │   │   └── pp_humanseg/
│   │   └── ocr/
│   │       └── ppocr/
│   └── ...
└── examples/
    └── rknn_xx_demo/
```

---

## 🗓️ 详细每日开发计划（优化版）

---

### 第一周：环境搭建与模型部署（12/18 - 12/24）

#### Day 1（12/18 周三）：获取 RKNN Model Zoo

**今日目标：** 下载官方仓库和预训练模型

| 任务 | 具体操作 | 时间 |
|------|----------|------|
| 克隆仓库 | `git clone https://github.com/airockchip/rknn_model_zoo` | 30分钟 |
| 下载模型 | 从云盘下载 RK3576 预编译 .rknn 模型 | 1小时 |
| 阅读文档 | 了解目录结构和使用方法 | 1小时 |

**命令：**
```bash
cd d:\rk3576
git clone https://github.com/airockchip/rknn_model_zoo.git
```

**完成标准：**
- [x] 仓库克隆完成
- [x] 至少下载 3 个预训练模型（YOLOv8、RetinaFace、YOLOv8-pose）

---

#### Day 2（12/19 周四）：RKNN-Toolkit2 环境（WSL/Linux）

**今日目标：** 配置模型转换工具

> [!IMPORTANT]
> **RKNN-Toolkit2 只支持 Linux！** Windows 用户必须使用 WSL。

| 任务 | 具体操作 |
|------|----------|
| 安装 WSL | Windows 用户需先安装 WSL2 |
| 克隆 rknn-toolkit2 仓库 | 包含安装包和文档 |
| 安装 RKNN-Toolkit2 | 从仓库 whl 文件安装 |
| 验证安装 | 导入测试 |

**安装命令（在 WSL/Linux 中执行）：**
```bash
# 1. 进入项目目录
cd /mnt/d/rk3576-ai-vision

# 2. 克隆 rknn-toolkit2 仓库（包含安装包）
git clone https://github.com/airockchip/rknn-toolkit2.git

# 3. 安装 RKNN-Toolkit2（Python 3.10 版本）
pip3 install ./rknn-toolkit2/rknn-toolkit2/packages/x86_64/rknn_toolkit2-2.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl

# 4. 验证安装
python3 -c "from rknn.api import RKNN; print('RKNN-Toolkit2 安装成功！')"
```

> [!NOTE]
> - 安装包路径：`rknn-toolkit2/rknn-toolkit2/packages/x86_64/`
> - 根据 Python 版本选择对应的 whl 文件（cp38/cp310/cp311 等）
> - 最新版本：v2.3.2

**完成标准：**
- [x] RKNN-Toolkit2 安装成功
- [x] 能正常导入 RKNN

---

#### Day 3（12/20 周五）：PC 端模型测试

**今日目标：** 在 PC 上验证预训练模型

| 任务 | 具体操作 |
|------|----------|
| 运行 YOLOv8 demo | 使用仓库自带示例 |
| 运行 RetinaFace demo | 人脸检测测试 |
| 理解推理流程 | 前处理 → 推理 → 后处理 |

**⚠️ 关键：统一预处理封装（避免 PC/板端结果不一致）**
```python
# common/preprocess.py - PC/板端通用
import cv2
import numpy as np

def preprocess(img, target_size=(640, 640)):
    """
    统一预处理：BGR→RGB + resize
    ⚠️ 不做 normalize，RKNN 模型内部处理
    """
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # ⚠️ 关键！
    img = cv2.resize(img, target_size)
    img = img.astype(np.uint8)  # ⚠️ 保持 uint8
    return img
```

**测试代码示例：**
```python
from rknn.api import RKNN
import cv2
from common.preprocess import preprocess  # 复用预处理

# 加载模型
rknn = RKNN()
rknn.load_rknn('./yolov8n.rknn')
rknn.init_runtime()

# 读取并预处理
img = cv2.imread('test.jpg')
img_input = preprocess(img)  # ✅ 统一预处理

# 推理
outputs = rknn.inference(inputs=[img_input])
print("推理完成，输出shape:", [o.shape for o in outputs])
```

**完成标准：**
- [x] YOLOv8 模型推理成功
- [x] RetinaFace 模型转换完成

---

#### Day 4-5（12/21-12/22 周六日）：开发板系统准备

**今日目标：** RK3576 开发板开机并配置环境

| 任务 | 具体操作 |
|------|----------|
| 烧录系统 | 使用 RKDevTool 刷固件 |
| 首次启动 | 连接串口/显示器 |
| 网络配置 | 有线/WiFi 连接 |
| SSH 连接 | 从 PC 远程登录 |

**开发板环境安装：**
```bash
# 更新系统
sudo apt update && sudo apt upgrade -y

# 安装 Python 和依赖
sudo apt install python3-pip python3-opencv -y

# 安装 rknn-lite2（板端推理库）
pip3 install rknn-lite2

# 验证
python3 -c "from rknnlite.api import RKNNLite; print('rknn-lite2 安装成功')"
```

**完成标准：**
- [ ] 开发板正常启动
- [ ] SSH 登录成功
- [ ] rknn-lite2 安装成功

---

#### Day 6-7（12/23-12/24 周一二）：第一个模型上板

**今日目标：** 在 RK3576 上运行 YOLOv8

| 任务 | 具体操作 |
|------|----------|
| 传输模型 | 将 .rknn 文件拷贝到板子 |
| 运行 demo | 使用官方示例代码 |
| 摄像头测试 | 实时检测 |
| 记录性能 | FPS、延迟 |

**NPU 核心分配策略：**
| 场景 | core_mask 设置 | 说明 |
|------|----------------|------|
| 单模型调试 | `NPU_CORE_0` | 稳定优先 |
| 多模型串行 | `NPU_CORE_AUTO` | 自动分配 |
| 双模型并行 | 不同 core | 如人脸+姿态 |
| UI + 推理 | 推理独立线程 | 避免阻塞 |

> [!IMPORTANT]
> **NPU / CPU 架构铁律（项目风险降一半）：**
> - ❗ 同一时间最多 **2 个 NPU 模型常驻**
> - ❗ QR / 条码 / 简单图像处理 → **CPU 插件**
> - ❗ UI 线程 **永不直接调用 NPU**

**NPU 调度优先级（系统设计思想）：**
| 优先级 | 任务类型 | 示例 |
|--------|----------|------|
| 1（最高） | 实时检测 | YOLO / Pose |
| 2 | 安全相关 | 跌倒 / 安全帽 |
| 3（最低） | 低频任务 | OCR / 人脸识别 |

**QR / 条码识别（纯 CPU）：**
| 环节 | 处理单元 | 说明 |
|------|----------|------|
| 图像采集 | CPU | OpenCV |
| 二维码/条码检测 | CPU | OpenCV / ZBar |
| 解码输出 | CPU | 不占用 NPU pipeline |

**OCR 文字识别（NPU + CPU 混合流水线）：**

> [!NOTE]
> OCR 作为 **低频触发任务**（非每帧执行），避免与实时检测模型争抢 NPU。

| 环节 | 处理单元 | 模型/方法 |
|------|----------|-----------|
| 文本检测 | **NPU** | DBNet（RKNN） |
| 文本识别 | **NPU** | PPOCR Rec（RKNN） |
| CTC 解码 | CPU | 后处理 |
| 文本拼接 | CPU | 字符串处理 |

**板端推理代码：**
```python
from rknnlite.api import RKNNLite
import cv2
from common.preprocess import preprocess  # ✅ 复用预处理
from common.postprocess import yolov8_postprocess  # ✅ 注意：v5/v8 后处理不同！

# 初始化
rknn = RKNNLite()
rknn.load_rknn('./yolov8n.rknn')
rknn.init_runtime(core_mask=RKNNLite.NPU_CORE_0)  # 单模型用 CORE_0

# 摄像头推理
cap = cv2.VideoCapture(0)
while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # ✅ 统一预处理
    img_input = preprocess(frame)
    
    # 推理
    outputs = rknn.inference(inputs=[img_input])
    
    # ✅ 统一后处理（注意区分 v5/v8）
    boxes, scores, classes = yolov8_postprocess(outputs)
    
    # ✅ UI：直接 OpenCV overlay（不用 Qt/Web）
    for box, cls in zip(boxes, classes):
        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)
    
    cv2.imshow('Detection', frame)
    if cv2.waitKey(1) == ord('q'):
        break

rknn.release()
```

**完成标准：**
- [ ] YOLOv8 在板子上运行成功
- [ ] 摄像头实时检测正常
- [ ] FPS >= 20（720P 输入 / 单模型 / USB 摄像头）

---

### 第二周：多功能集成（12/25 - 12/31）

#### Day 8-9：人脸检测与识别

| 任务 | 模型 |
|------|------|
| 人脸检测 | RetinaFace |
| 人脸特征提取 | ArcFace / MobileFaceNet |
| 1:N 识别 | 特征比对 |

#### Day 10-11：人体姿态与跌倒检测

| 任务 | 模型/方法 |
|------|------|
| 人体骨骼点检测 | MoveNet |
| **跌倒判断（状态机）** | 见下方公式 |
| 文字识别 | PPOCR |

**⚠️ 跌倒检测核心逻辑（不要单帧判断！）：**
```python
# common/fall_detector.py
class FallDetector:
    def __init__(self, threshold_frames=15):
        self.history = []  # 存储连续帧状态
        self.threshold_frames = threshold_frames
    
    def detect(self, keypoints):
        """
        跌倒 = 关键点高度变化 + 身体主轴角度 + 持续时间
        """
        # 计算身体主轴角度（头-臀连线与垂直方向夹角）
        head = keypoints[0]   # 头部关键点
        hip = keypoints[11]   # 臀部关键点
        angle = self._calc_angle(head, hip)
        
        # 状态判断
        is_falling = angle > 60  # 倾斜超过60度
        self.history.append(is_falling)
        
        # 保留最近N帧
        if len(self.history) > self.threshold_frames:
            self.history.pop(0)
        
        # ✅ 连续N帧都是倾倒状态才判定为跌倒
        return sum(self.history) >= self.threshold_frames * 0.8
```

#### Day 12-14：功能整合

| 任务 | 内容 |
|------|------|
| **统一模型基类** | BaseRKNNModel（见下方） |
| 多模型切换 | 统一推理框架 |
| UI 界面 | **OpenCV imshow + overlay**（不用 Qt/Web） |
| 性能优化 | 多线程、零拷贝 |

**统一模型基类（多模型整合必备）：**
```python
# common/base_model.py
from rknnlite.api import RKNNLite

class BaseRKNNModel:
    """所有模型的基类，统一 load/infer/release"""
    
    def __init__(self, model_path, core_mask=RKNNLite.NPU_CORE_0):
        self.rknn = RKNNLite()
        self.rknn.load_rknn(model_path)
        self.rknn.init_runtime(core_mask=core_mask)
    
    def preprocess(self, img):
        """子类可重写"""
        raise NotImplementedError
    
    def postprocess(self, outputs):
        """子类可重写"""
        raise NotImplementedError
    
    def infer(self, img):
        img_input = self.preprocess(img)
        outputs = self.rknn.inference(inputs=[img_input])
        return self.postprocess(outputs)
    
    def release(self):
        self.rknn.release()
```

> [!CAUTION]
> **UI 警告：千万别中后期突然想"做个好看的界面"！**
> 这是 80% 嵌入式 AI 项目翻车的起点。
> RK3576 的价值在 NPU，不在 UI。坚持 OpenCV imshow！
>
> **工程定位：** UI 仅作为调试与结果展示，不作为核心功能模块。

---

## 📊 功能实现进度跟踪

| 功能 | 模型 | PC验证 | 上板运行 | 优化完成 |
|------|------|--------|----------|----------|
| 目标检测 | YOLOv8n | ☑ | ☐ | ☐ |
| 人脸检测 | RetinaFace | ☐ | ☐ | ☐ |
| 人脸识别 | ArcFace | ☐ | ☐ | ☐ |
| 人体姿态 | MoveNet | ☐ | ☐ | ☐ |
| 跌倒检测 | 规则判断 | ☐ | ☐ | ☐ |
| OCR文字 | PPOCR | ☐ | ☐ | ☐ |
| 车牌识别 | LPRNet | ☐ | ☐ | ☐ |
| 二维码 | OpenCV | ☐ | ☐ | ☐ |
| 安全帽 | YOLOv8自训练 | ☐ | ☐ | ☐ |
| 手势识别 | MediaPipe | ☐ | ☐ | ☐ |

---

## 📁 项目目录结构

```
d:\rk3576\
├── rknn_model_zoo/          # 官方模型仓库
│   ├── models/              # 预训练模型
│   └── examples/            # 示例代码
├── models/                  # 自己使用的模型
│   ├── yolov8n.rknn
│   ├── retinaface.rknn
│   ├── arcface.rknn
│   └── movenet.rknn
├── src/                     # 自己的代码
│   ├── common/              # ✅ 公共模块（复用性高）
│   │   ├── base_model.py    # 模型基类
│   │   ├── preprocess.py    # 统一预处理
│   │   ├── postprocess.py   # 统一后处理（区分v5/v8）
│   │   ├── camera.py        # 摄像头封装
│   │   └── fall_detector.py # 跌倒检测状态机
│   ├── detector.py          # 目标检测
│   ├── face.py              # 人脸识别
│   ├── pose.py              # 姿态估计
│   └── main.py              # 主程序
├── datasets/                # 数据集（如需训练）
└── docs/                    # 文档
```

---

## ⚠️ 硬件清单确认

| 项目 | 型号/规格 | 已备 |
|------|----------|------|
| RK3576 开发板 | 瑞芯微官方 | ☐ |
| 电源 | 12V/2A 或 5V/3A | ☐ |
| USB 摄像头 | 720P/1080P | ☐ |
| TF 卡 | ≥16GB | ☐ |
| USB 串口线 | CH340/CP2102 | ☐ |
| 网线 | RJ45 | ☐ |

---

## 🔗 重要资源链接

| 资源 | 链接 |
|------|------|
| **RKNN Model Zoo** | https://github.com/airockchip/rknn_model_zoo |
| **RKNN-Toolkit2** | https://github.com/airockchip/rknn-toolkit2 |
| **瑞芯微开发者中心** | https://www.rock-chips.com/a/cn/downloadcenter/index.html |
| **RK3576 文档** | SDK 包内 docs 目录 |

---

## ✅ 当前进度（12/22）

- [x] 克隆 RKNN Model Zoo 仓库
- [x] 下载 YOLOv8、RetinaFace、YOLOv8-pose 预训练模型
- [x] RKNN-Toolkit2 安装成功
- [x] 模型转换完成（ONNX → RKNN）
- [x] PC 端 YOLOv8 推理测试成功
- [x] 统一配置模块 config.py
- [x] 统一检测器接口 detector.py
- [x] zlog 日志系统集成
- [x] main.py 测试通过（检测到 5 个目标）
- [ ] 开发板到货
- [ ] 板端部署测试

---

> 💡 **核心策略：用现成的，不重复造轮子！**
