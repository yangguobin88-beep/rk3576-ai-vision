# RK3576 AI è§†è§‰é¡¹ç›® - å®Œæ•´ä»£ç æ±‡æ€»

> ğŸ“… ç”Ÿæˆæ—¥æœŸï¼š2025-12-22
> ğŸ“ åŒ…å« src ç›®å½•ä¸‹æ‰€æœ‰ä»£ç æ–‡ä»¶

---

## ç›®å½•

1. [main.py](#mainpy)
2. [common/\_\_init\_\_.py](#common__init__py)
3. [common/config.py](#commonconfigpy)
4. [common/preprocess.py](#commonpreprocesspy)
5. [common/postprocess.py](#commonpostprocesspy)
6. [common/base_model.py](#commonbase_modelpy)
7. [common/camera.py](#commoncamerapy)
8. [common/fall_detector.py](#commonfall_detectorpy)
9. [common/logger.py](#commonloggerpy)
10. [common/detector.py](#commondetectorpy)
11. [common/yolo_detector.py](#commonyolo_detectorpy)

---

## main.py

```python
"""
RK3576 AI è§†è§‰é¡¹ç›® - ä¸»ç¨‹åºå…¥å£

ä½¿ç”¨æ–¹æ³•ï¼š
    # å›¾ç‰‡æ£€æµ‹
    python main.py --image test.jpg --model ../models/yolov8n.onnx
    
    # æ‘„åƒå¤´æ£€æµ‹
    python main.py --camera 0 --model ../models/yolov8n.onnx
    
    # æ¿ç«¯è¿è¡Œ
    python3 main.py --camera 0 --model ../models/yolov8.rknn
"""
import cv2
import argparse
import sys
import os

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from common.detector import create_detector
from common.camera import Camera, FPSCounter
from common.config import OBJ_THRESH, NMS_THRESH, CAMERA_WIDTH, CAMERA_HEIGHT
from common.logger import zlog


def draw_results(img, boxes, classes, scores, names):
    """ç»˜åˆ¶æ£€æµ‹ç»“æœ"""
    if boxes is None:
        return img
    
    img_draw = img.copy()
    for box, cls, score, name in zip(boxes, classes, scores, names):
        x1, y1, x2, y2 = map(int, box)
        color = (0, 255, 0) if name == "person" else (255, 0, 0)
        
        cv2.rectangle(img_draw, (x1, y1), (x2, y2), color, 2)
        label = f"{name}: {score:.2f}"
        cv2.putText(img_draw, label, (x1, y1 - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
    
    return img_draw


def run_image(args):
    """å›¾ç‰‡æ£€æµ‹"""
    zlog.info(f"[å›¾ç‰‡æ¨¡å¼] {args.image}")
    
    img = cv2.imread(args.image)
    if img is None:
        zlog.error(f"æ— æ³•è¯»å–å›¾ç‰‡: {args.image}")
        return
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = create_detector(args.model, args.conf, args.nms)
    
    # æ£€æµ‹
    boxes, classes, scores, names = detector.detect(img)
    
    # æ‰“å°ç»“æœ
    if boxes is not None:
        zlog.info(f"æ£€æµ‹åˆ° {len(boxes)} ä¸ªç›®æ ‡")
        for name, score in zip(names, scores):
            zlog.info(f"  {name}: {score:.2f}")
    else:
        zlog.info("æœªæ£€æµ‹åˆ°ç›®æ ‡")
    
    # ç»˜åˆ¶å¹¶ä¿å­˜
    result = draw_results(img, boxes, classes, scores, names)
    output = args.output if args.output else "result.jpg"
    cv2.imwrite(output, result)
    zlog.info(f"ç»“æœä¿å­˜: {output}")
    
    # æ˜¾ç¤º
    if args.show:
        cv2.imshow("Result", result)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    
    detector.release()


def run_camera(args):
    """æ‘„åƒå¤´æ£€æµ‹"""
    zlog.info(f"[æ‘„åƒå¤´æ¨¡å¼] è®¾å¤‡ {args.camera}")
    
    # åˆ›å»ºæ£€æµ‹å™¨å’Œæ‘„åƒå¤´
    detector = create_detector(args.model, args.conf, args.nms)
    camera = Camera(args.camera, args.width, args.height)
    fps_counter = FPSCounter()
    
    zlog.info("æŒ‰ 'q' é€€å‡º")
    
    try:
        camera.start()
        
        while True:
            frame = camera.read()
            if frame is None:
                continue
            
            # æ£€æµ‹
            boxes, classes, scores, names = detector.detect(frame)
            
            # ç»˜åˆ¶
            frame = draw_results(frame, boxes, classes, scores, names)
            
            # FPS
            fps_counter.tick()
            fps = fps_counter.get_fps()
            count = len(boxes) if boxes is not None else 0
            cv2.putText(frame, f"FPS: {fps:.1f} | Objects: {count}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            cv2.imshow('RK3576 AI Demo', frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    
    finally:
        camera.release()
        detector.release()
        cv2.destroyAllWindows()
        zlog.info("ç¨‹åºé€€å‡º")


def main():
    parser = argparse.ArgumentParser(description='RK3576 AI è§†è§‰æ¼”ç¤º')
    parser.add_argument('--image', type=str, help='å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--camera', type=int, help='æ‘„åƒå¤´è®¾å¤‡å·')
    parser.add_argument('--model', type=str, default='../models/yolov8n.onnx', help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--conf', type=float, default=OBJ_THRESH, help='ç½®ä¿¡åº¦é˜ˆå€¼')
    parser.add_argument('--nms', type=float, default=NMS_THRESH, help='NMS é˜ˆå€¼')
    parser.add_argument('--width', type=int, default=CAMERA_WIDTH)
    parser.add_argument('--height', type=int, default=CAMERA_HEIGHT)
    parser.add_argument('--output', type=str, help='è¾“å‡ºè·¯å¾„')
    parser.add_argument('--show', action='store_true', help='æ˜¾ç¤ºçª—å£')
    
    args = parser.parse_args()
    
    zlog.info("=" * 40)
    zlog.info("RK3576 AI è§†è§‰æ¼”ç¤º")
    zlog.info(f"æ¨¡å‹: {args.model}")
    zlog.info("=" * 40)
    
    if args.image:
        run_image(args)
    elif args.camera is not None:
        run_camera(args)
    else:
        zlog.warn("è¯·æŒ‡å®šè¾“å…¥æºï¼š--image æˆ– --camera")


if __name__ == '__main__':
    main()
```

---

## common/\_\_init\_\_.py

```python
# common/__init__.py
from .config import MODEL_INPUT_SIZE, OBJ_THRESH, NMS_THRESH, COCO_CLASSES
from .preprocess import preprocess, preprocess_with_letterbox, restore_coords
from .base_model import BaseRKNNModel
from .postprocess import yolov8_postprocess, nms, get_class_name
from .camera import Camera, FPSCounter
from .fall_detector import FallDetector
from .yolo_detector import YOLOv8Detector
from .detector import create_detector, ONNXDetector, RKNNDetector
from .logger import zlog
```

---

## common/config.py

```python
"""
å…¨å±€é…ç½®æ¨¡å— - ç»Ÿä¸€ç®¡ç†é¡¹ç›®å‚æ•°

âš ï¸ æœ¬æ–‡ä»¶ä¸ºå…¨å±€é…ç½®ï¼Œä¿®æ”¹å‚æ•°å‰è¯·ç¡®è®¤å¯¹æ•´ä½“ç³»ç»Ÿå½±å“
âš ï¸ é¢„å¤„ç†/åå¤„ç†ä¾èµ–åŒä¸€ä»½å‚æ•°ï¼Œè¯·å‹¿å•ç‹¬ä¿®æ”¹
"""

# ==================== æ¨¡å‹è¾“å…¥é…ç½® ====================

# æ¨¡å‹è¾“å…¥å°ºå¯¸ (width, height)
# âš ï¸ é¢„å¤„ç†å’Œåå¤„ç†å¿…é¡»ä½¿ç”¨ç›¸åŒçš„å°ºå¯¸
MODEL_INPUT_SIZE = (640, 640)

# ==================== YOLOv8 æ£€æµ‹é…ç½® ====================

# ç½®ä¿¡åº¦é˜ˆå€¼ï¼šä½äºæ­¤å€¼çš„æ£€æµ‹æ¡†è¢«ä¸¢å¼ƒ
OBJ_THRESH = 0.25

# NMS é˜ˆå€¼ï¼šIoU é«˜äºæ­¤å€¼çš„é‡å æ¡†è¢«åˆå¹¶
NMS_THRESH = 0.45

# ==================== æ‘„åƒå¤´é…ç½® ====================
# âš ï¸ æ‘„åƒå¤´åŸå§‹åˆ†è¾¨ç‡ï¼ˆâ‰  æ¨¡å‹è¾“å…¥å°ºå¯¸ï¼‰
# å›¾åƒä¼šå…ˆä»æ‘„åƒå¤´é‡‡é›†ï¼Œå† resize åˆ° MODEL_INPUT_SIZE

# é»˜è®¤æ‘„åƒå¤´
CAMERA_SOURCE = 0

# æ‘„åƒå¤´åˆ†è¾¨ç‡
CAMERA_WIDTH = 1280
CAMERA_HEIGHT = 720

# å¸§ç‡
CAMERA_FPS = 30

# ==================== è·Œå€’æ£€æµ‹é…ç½® ====================

# åˆ¤æ–­çª—å£å¸§æ•°
FALL_THRESHOLD_FRAMES = 15

# è§’åº¦é˜ˆå€¼ï¼ˆåº¦ï¼‰
FALL_ANGLE_THRESHOLD = 60

# ç¡®è®¤æ¯”ä¾‹
FALL_CONFIRM_RATIO = 0.8

# ==================== COCO ç±»åˆ« ====================

COCO_CLASSES = (
    "person", "bicycle", "car", "motorbike", "aeroplane", "bus", "train", "truck", "boat", "traffic light",
    "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse", "sheep", "cow",
    "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella", "handbag", "tie", "suitcase", "frisbee",
    "skis", "snowboard", "sports ball", "kite", "baseball bat", "baseball glove", "skateboard", "surfboard",
    "tennis racket", "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
    "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair", "sofa",
    "pottedplant", "bed", "diningtable", "toilet", "tvmonitor", "laptop", "mouse", "remote", "keyboard",
    "cell phone", "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase",
    "scissors", "teddy bear", "hair drier", "toothbrush"
)
```

---

## common/preprocess.py

```python
"""
ç»Ÿä¸€é¢„å¤„ç†æ¨¡å— - PC/æ¿ç«¯é€šç”¨
"""
import cv2
import numpy as np
from .config import MODEL_INPUT_SIZE


def preprocess(img, target_size=None):
    """
    ç»Ÿä¸€é¢„å¤„ç†ï¼šBGRâ†’RGB + resize
    
    Args:
        img: OpenCV è¯»å–çš„ BGR å›¾åƒ
        target_size: ç›®æ ‡å°ºå¯¸ï¼Œé»˜è®¤ä½¿ç”¨ config.MODEL_INPUT_SIZE
    
    Returns:
        å¤„ç†åçš„ RGB å›¾åƒï¼Œuint8 æ ¼å¼
    
    æ³¨æ„ï¼š
        - âš ï¸ ä¸åš normalizeï¼ŒRKNN æ¨¡å‹å†…éƒ¨å¤„ç†
        - âš ï¸ ä¿æŒ uint8ï¼Œä¸è½¬ float32
    """
    if target_size is None:
        target_size = MODEL_INPUT_SIZE
    
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, target_size)
    img = img.astype(np.uint8)
    return img


def preprocess_with_letterbox(img, target_size=None, color=(0, 0, 0)):
    """
    å¸¦ letterbox çš„é¢„å¤„ç†ï¼ˆä¿æŒå®½é«˜æ¯”ï¼‰
    
    Args:
        img: OpenCV è¯»å–çš„ BGR å›¾åƒ
        target_size: ç›®æ ‡å°ºå¯¸ï¼Œé»˜è®¤ä½¿ç”¨ config.MODEL_INPUT_SIZE
        color: å¡«å……é¢œè‰²ï¼Œé»˜è®¤é»‘è‰² (0,0,0)
    
    Returns:
        img_padded: å¤„ç†åçš„ RGB å›¾åƒ
        scale: ç¼©æ”¾æ¯”ä¾‹
        pad: å¡«å……åç§» (pad_x, pad_y)
    """
    if target_size is None:
        target_size = MODEL_INPUT_SIZE
    
    h, w = img.shape[:2]
    target_w, target_h = target_size
    scale = min(target_w / w, target_h / h)
    new_w, new_h = int(w * scale), int(h * scale)
    
    img_resized = cv2.resize(img, (new_w, new_h))
    img_padded = np.full((target_h, target_w, 3), color, dtype=np.uint8)
    
    pad_x = (target_w - new_w) // 2
    pad_y = (target_h - new_h) // 2
    img_padded[pad_y:pad_y+new_h, pad_x:pad_x+new_w] = img_resized
    img_padded = cv2.cvtColor(img_padded, cv2.COLOR_BGR2RGB)
    
    return img_padded, scale, (pad_x, pad_y)


def restore_coords(boxes, scale, pad):
    """
    å°† letterbox åæ ‡è¿˜åŸåˆ°åŸå›¾åæ ‡
    
    Args:
        boxes: æ£€æµ‹æ¡† [[x1,y1,x2,y2], ...]
        scale: letterbox ç¼©æ”¾æ¯”ä¾‹
        pad: letterbox å¡«å……åç§» (pad_x, pad_y)
    
    Returns:
        è¿˜åŸåçš„æ£€æµ‹æ¡†åæ ‡
    """
    if boxes is None:
        return None
    
    pad_x, pad_y = pad
    boxes = boxes.copy()
    boxes[:, [0, 2]] = (boxes[:, [0, 2]] - pad_x) / scale
    boxes[:, [1, 3]] = (boxes[:, [1, 3]] - pad_y) / scale
    return boxes
```

---

## common/postprocess.py

```python
"""
YOLO åå¤„ç†æ¨¡å— - YOLOv8 å®Œæ•´å®ç°ï¼ˆçº¯ numpyï¼Œæ—  torch ä¾èµ–ï¼‰
å‚è€ƒï¼šrknn_model_zoo/examples/yolov8/python/yolov8.py
"""
import numpy as np
from .config import MODEL_INPUT_SIZE, OBJ_THRESH, NMS_THRESH, COCO_CLASSES


def _softmax(x, axis=2):
    """Numpy å®ç°çš„ softmax"""
    x_exp = np.exp(x - np.max(x, axis=axis, keepdims=True))
    return x_exp / np.sum(x_exp, axis=axis, keepdims=True)


def _dfl(position):
    """
    Distribution Focal Loss (DFL) - è§£ç è¾¹ç•Œæ¡†
    âœ… çº¯ numpy å®ç°ï¼Œæ¿ç«¯å‹å¥½
    """
    n, c, h, w = position.shape
    p_num = 4
    mc = c // p_num
    y = position.reshape(n, p_num, mc, h, w)
    
    # softmax (numpy å®ç°)
    y = _softmax(y, axis=2)
    
    # åŠ æƒæ±‚å’Œ
    acc_metrix = np.arange(mc).astype(np.float32).reshape(1, 1, mc, 1, 1)
    y = np.sum(y * acc_metrix, axis=2)
    return y


def _box_process(position, img_size=None):
    """å°†æ¨¡å‹è¾“å‡ºè½¬æ¢ä¸º xyxy åæ ‡"""
    if img_size is None:
        img_size = MODEL_INPUT_SIZE
    
    grid_h, grid_w = position.shape[2:4]
    col, row = np.meshgrid(np.arange(0, grid_w), np.arange(0, grid_h))
    col = col.reshape(1, 1, grid_h, grid_w)
    row = row.reshape(1, 1, grid_h, grid_w)
    grid = np.concatenate((col, row), axis=1)
    stride = np.array([img_size[1] // grid_h, img_size[0] // grid_w]).reshape(1, 2, 1, 1)

    position = _dfl(position)
    box_xy = grid + 0.5 - position[:, 0:2, :, :]
    box_xy2 = grid + 0.5 + position[:, 2:4, :, :]
    xyxy = np.concatenate((box_xy * stride, box_xy2 * stride), axis=1)

    return xyxy


def _filter_boxes(boxes, box_confidences, box_class_probs, obj_thresh=None):
    """è¿‡æ»¤ä½ç½®ä¿¡åº¦çš„æ£€æµ‹æ¡†"""
    if obj_thresh is None:
        obj_thresh = OBJ_THRESH
    
    box_confidences = box_confidences.reshape(-1)
    
    class_max_score = np.max(box_class_probs, axis=-1)
    classes = np.argmax(box_class_probs, axis=-1)

    _class_pos = np.where(class_max_score * box_confidences >= obj_thresh)
    scores = (class_max_score * box_confidences)[_class_pos]

    boxes = boxes[_class_pos]
    classes = classes[_class_pos]

    return boxes, classes, scores


def nms(boxes, scores, iou_threshold=None):
    """éæå¤§å€¼æŠ‘åˆ¶ (NMS)"""
    if iou_threshold is None:
        iou_threshold = NMS_THRESH
    
    if len(boxes) == 0:
        return np.array([])
    
    x = boxes[:, 0]
    y = boxes[:, 1]
    w = boxes[:, 2] - boxes[:, 0]
    h = boxes[:, 3] - boxes[:, 1]

    areas = w * h
    order = scores.argsort()[::-1]

    keep = []
    while order.size > 0:
        i = order[0]
        keep.append(i)

        if order.size == 1:
            break

        xx1 = np.maximum(x[i], x[order[1:]])
        yy1 = np.maximum(y[i], y[order[1:]])
        xx2 = np.minimum(x[i] + w[i], x[order[1:]] + w[order[1:]])
        yy2 = np.minimum(y[i] + h[i], y[order[1:]] + h[order[1:]])

        w1 = np.maximum(0.0, xx2 - xx1 + 0.00001)
        h1 = np.maximum(0.0, yy2 - yy1 + 0.00001)
        inter = w1 * h1

        ovr = inter / (areas[i] + areas[order[1:]] - inter)
        inds = np.where(ovr <= iou_threshold)[0]
        order = order[inds + 1]

    return np.array(keep)


def yolov8_postprocess(outputs, obj_thresh=None, nms_thresh=None, img_size=None):
    """
    YOLOv8 åå¤„ç†å®Œæ•´å®ç°ï¼ˆçº¯ numpyï¼Œæ¿ç«¯å‹å¥½ï¼‰
    
    Args:
        outputs: æ¨¡å‹è¾“å‡ºï¼ˆå¤šä¸ª tensorï¼‰
        obj_thresh: ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œé»˜è®¤ä½¿ç”¨ config.OBJ_THRESH
        nms_thresh: NMS é˜ˆå€¼ï¼Œé»˜è®¤ä½¿ç”¨ config.NMS_THRESH
        img_size: è¾“å…¥å›¾åƒå°ºå¯¸ï¼Œé»˜è®¤ä½¿ç”¨ config.MODEL_INPUT_SIZE
    
    Returns:
        boxes: æ£€æµ‹æ¡†åæ ‡ [[x1,y1,x2,y2], ...]
        classes: ç±»åˆ« ID [0, 5, ...]
        scores: ç½®ä¿¡åº¦ [0.88, 0.85, ...]
    """
    if obj_thresh is None:
        obj_thresh = OBJ_THRESH
    if nms_thresh is None:
        nms_thresh = NMS_THRESH
    if img_size is None:
        img_size = MODEL_INPUT_SIZE
    
    boxes, scores, classes_conf = [], [], []
    default_branch = 3
    pair_per_branch = len(outputs) // default_branch

    # å¤„ç† 3 ä¸ªä¸åŒå°ºåº¦çš„è¾“å‡º
    for i in range(default_branch):
        boxes.append(_box_process(outputs[pair_per_branch * i], img_size))
        classes_conf.append(outputs[pair_per_branch * i + 1])
        scores.append(np.ones_like(outputs[pair_per_branch * i + 1][:, :1, :, :], dtype=np.float32))

    def sp_flatten(_in):
        ch = _in.shape[1]
        _in = _in.transpose(0, 2, 3, 1)
        return _in.reshape(-1, ch)

    boxes = [sp_flatten(_v) for _v in boxes]
    classes_conf = [sp_flatten(_v) for _v in classes_conf]
    scores = [sp_flatten(_v) for _v in scores]

    boxes = np.concatenate(boxes)
    classes_conf = np.concatenate(classes_conf)
    scores = np.concatenate(scores)

    # è¿‡æ»¤ä½ç½®ä¿¡åº¦
    boxes, classes, scores = _filter_boxes(boxes, scores, classes_conf, obj_thresh)

    # æŒ‰ç±»åˆ«åˆ†åˆ«è¿›è¡Œ NMS
    nboxes, nclasses, nscores = [], [], []
    for c in set(classes):
        inds = np.where(classes == c)
        b = boxes[inds]
        cls = classes[inds]
        s = scores[inds]
        keep = nms(b, s, nms_thresh)

        if len(keep) != 0:
            nboxes.append(b[keep])
            nclasses.append(cls[keep])
            nscores.append(s[keep])

    if not nclasses and not nscores:
        return None, None, None

    boxes = np.concatenate(nboxes)
    classes = np.concatenate(nclasses)
    scores = np.concatenate(nscores)

    return boxes, classes, scores


def yolov5_postprocess(outputs, conf_threshold=0.5, iou_threshold=0.45):
    """YOLOv5 åå¤„ç†ï¼ˆanchor-basedï¼‰- å¾…å®ç°"""
    raise NotImplementedError("YOLOv5 åå¤„ç†å¾…å®ç°ï¼Œè¯·å‚è€ƒ rknn_model_zoo ç¤ºä¾‹")


def get_class_name(class_id):
    """æ ¹æ®ç±»åˆ« ID è·å–ç±»åˆ«åç§°"""
    if 0 <= class_id < len(COCO_CLASSES):
        return COCO_CLASSES[class_id]
    return f"class_{class_id}"
```

---

## common/base_model.py

```python
"""
RKNN æ¨¡å‹åŸºç±» - ç»Ÿä¸€ load/infer/release
"""


class BaseRKNNModel:
    """æ‰€æœ‰ RKNN æ¨¡å‹çš„åŸºç±»"""
    
    def __init__(self, model_path, core_mask=None):
        try:
            from rknnlite.api import RKNNLite
            self.rknn = RKNNLite()
            self.is_lite = True
        except ImportError:
            from rknn.api import RKNN
            self.rknn = RKNN()
            self.is_lite = False
        
        ret = self.rknn.load_rknn(model_path)
        if ret != 0:
            raise RuntimeError(f"åŠ è½½æ¨¡å‹å¤±è´¥: {model_path}")
        
        if self.is_lite and core_mask is not None:
            ret = self.rknn.init_runtime(core_mask=core_mask)
        else:
            ret = self.rknn.init_runtime()
        
        if ret != 0:
            raise RuntimeError("åˆå§‹åŒ–è¿è¡Œæ—¶å¤±è´¥")
        
        self.model_path = model_path
    
    def preprocess(self, img):
        raise NotImplementedError
    
    def postprocess(self, outputs):
        raise NotImplementedError
    
    def infer(self, img):
        img_input = self.preprocess(img)
        outputs = self.rknn.inference(inputs=[img_input])
        return self.postprocess(outputs)
    
    def release(self):
        if self.rknn is not None:
            self.rknn.release()
            self.rknn = None
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.release()
        return False
```

---

## common/camera.py

```python
"""
æ‘„åƒå¤´å°è£…æ¨¡å—
"""
import cv2
import threading
import time


class Camera:
    """æ‘„åƒå¤´å°è£…ç±» - æ”¯æŒå¤šçº¿ç¨‹é‡‡é›†"""
    
    def __init__(self, source=0, width=1280, height=720, fps=30):
        self.source = source
        self.width = width
        self.height = height
        self.fps = fps
        self.cap = None
        self.frame = None
        self.running = False
        self.thread = None
        self.lock = threading.Lock()
    
    def open(self):
        self.cap = cv2.VideoCapture(self.source)
        if not self.cap.isOpened():
            raise RuntimeError(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´: {self.source}")
        
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.height)
        self.cap.set(cv2.CAP_PROP_FPS, self.fps)
        return self
    
    def _capture_loop(self):
        while self.running:
            ret, frame = self.cap.read()
            if ret:
                with self.lock:
                    self.frame = frame
    
    def start(self):
        if self.cap is None:
            self.open()
        self.running = True
        self.thread = threading.Thread(target=self._capture_loop, daemon=True)
        self.thread.start()
        time.sleep(0.1)
        return self
    
    def read(self):
        with self.lock:
            return self.frame.copy() if self.frame is not None else None
    
    def stop(self):
        self.running = False
        if self.thread:
            self.thread.join(timeout=1.0)
    
    def release(self):
        self.stop()
        if self.cap:
            self.cap.release()
    
    def __enter__(self):
        return self.start()
    
    def __exit__(self, *args):
        self.release()


class FPSCounter:
    """FPS è®¡æ•°å™¨"""
    def __init__(self, window=30):
        self.times = []
        self.window = window
    
    def tick(self):
        self.times.append(time.time())
        if len(self.times) > self.window:
            self.times.pop(0)
    
    def get_fps(self):
        if len(self.times) < 2:
            return 0.0
        return (len(self.times) - 1) / (self.times[-1] - self.times[0])
```

---

## common/fall_detector.py

```python
"""
è·Œå€’æ£€æµ‹çŠ¶æ€æœº
"""
import numpy as np
import time


class FallDetector:
    """
    è·Œå€’æ£€æµ‹å™¨ - åŸºäºå§¿æ€å…³é”®ç‚¹çš„çŠ¶æ€æœº
    æ ¸å¿ƒé€»è¾‘ï¼šè·Œå€’ = å…³é”®ç‚¹é«˜åº¦å˜åŒ– + èº«ä½“ä¸»è½´è§’åº¦ + æŒç»­æ—¶é—´
    """
    
    def __init__(self, threshold_frames=15, angle_threshold=60, confirm_ratio=0.8):
        self.threshold_frames = threshold_frames
        self.angle_threshold = angle_threshold
        self.confirm_ratio = confirm_ratio
        self.history = []
        self.last_fall_time = None
    
    def detect(self, keypoints):
        if keypoints is None or len(keypoints) < 12:
            return False, 0
        
        angle = self._calc_body_angle(keypoints)
        is_falling = angle > self.angle_threshold
        self.history.append(is_falling)
        
        if len(self.history) > self.threshold_frames:
            self.history.pop(0)
        
        if len(self.history) >= self.threshold_frames:
            fall_ratio = sum(self.history) / len(self.history)
            is_fall = fall_ratio >= self.confirm_ratio
            if is_fall:
                self.last_fall_time = time.time()
            return is_fall, angle
        
        return False, angle
    
    def _calc_body_angle(self, keypoints):
        try:
            head = keypoints[0][:2]
            hip = [(keypoints[11][0] + keypoints[12][0]) / 2,
                   (keypoints[11][1] + keypoints[12][1]) / 2]
            dx = head[0] - hip[0]
            dy = head[1] - hip[1]
            angle = np.abs(np.arctan2(dx, -dy) * 180 / np.pi)
            return angle
        except:
            return 0
    
    def reset(self):
        self.history.clear()
        self.last_fall_time = None
```

---

## common/logger.py

```python
"""
ç»Ÿä¸€æ—¥å¿—æ¨¡å— - æ”¯æŒ PCï¼ˆloggingï¼‰å’Œæ¿ç«¯ï¼ˆzlogï¼‰

ä½¿ç”¨æ–¹å¼:
    from common.logger import zlog
    zlog.info("æ¨¡å‹åŠ è½½å®Œæˆ")
    zlog.error("åŠ è½½å¤±è´¥")

PCç«¯: è‡ªåŠ¨ä½¿ç”¨ Python logging
æ¿ç«¯: è‡ªåŠ¨ä½¿ç”¨ zlogï¼ˆéœ€è¦ libzlog.soï¼‰
"""
import os
import sys
import logging
from datetime import datetime



class ZLogWrapper:
    """
    zlog å°è£…ï¼ˆæ¿ç«¯ä½¿ç”¨ï¼‰
    é€šè¿‡ ctypes è°ƒç”¨ libzlog.so
    """
    
    def __init__(self, conf_path="/etc/zlog.conf", category="default"):
        import ctypes
        
        self.zlog = ctypes.CDLL("libzlog.so")
        ret = self.zlog.zlog_init(conf_path.encode())
        if ret != 0:
            raise RuntimeError(f"zlog init failed: {conf_path}")
        
        self.zc = self.zlog.zlog_get_category(category.encode())
        if not self.zc:
            raise RuntimeError(f"zlog get category failed: {category}")
        
        self._category = category
    
    def debug(self, msg):
        self.zlog.zlog_debug(self.zc, str(msg).encode())
    
    def info(self, msg):
        self.zlog.zlog_info(self.zc, str(msg).encode())
    
    def warn(self, msg):
        self.zlog.zlog_warn(self.zc, str(msg).encode())
    
    def warning(self, msg):
        self.warn(msg)
    
    def error(self, msg):
        self.zlog.zlog_error(self.zc, str(msg).encode())
    
    def fatal(self, msg):
        self.zlog.zlog_fatal(self.zc, str(msg).encode())


class ColoredLogger:
    """
    å½©è‰²æ§åˆ¶å°æ—¥å¿—ï¼ˆPC å¼€å‘é˜¶æ®µä½¿ç”¨ï¼‰
    åŸºäº Python loggingï¼Œå¸¦é¢œè‰²è¾“å‡º
    """
    
    # æ—¥å¿—çº§åˆ«é¢œè‰²
    COLORS = {
        'DEBUG': '\033[36m',    # é’è‰²
        'INFO': '\033[32m',     # ç»¿è‰²
        'WARNING': '\033[33m',  # é»„è‰²
        'ERROR': '\033[31m',    # çº¢è‰²
        'FATAL': '\033[35m',    # ç´«è‰²
        'RESET': '\033[0m'      # é‡ç½®
    }
    
    def __init__(self, name="rk3576", level=logging.INFO, log_file=None):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)
        self.logger.handlers.clear()
        
        # æ§åˆ¶å°è¾“å‡ºï¼ˆå¸¦é¢œè‰²ï¼‰
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(level)
        console_format = logging.Formatter(
            fmt='%(asctime)s [%(levelname)s] %(message)s',
            datefmt='%H:%M:%S'
        )
        console_handler.setFormatter(console_format)
        self.logger.addHandler(console_handler)
        
        # æ–‡ä»¶è¾“å‡ºï¼ˆå¯é€‰ï¼‰
        if log_file:
            file_handler = logging.FileHandler(log_file, encoding='utf-8')
            file_handler.setLevel(level)
            file_format = logging.Formatter(
                fmt='%(asctime)s [%(levelname)s] %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S'
            )
            file_handler.setFormatter(file_format)
            self.logger.addHandler(file_handler)
    
    def _colorize(self, level, msg):
        """ç»™æ¶ˆæ¯æ·»åŠ é¢œè‰²ï¼ˆä»…ç»ˆç«¯ï¼‰"""
        if sys.stdout.isatty():
            color = self.COLORS.get(level, '')
            reset = self.COLORS['RESET']
            return f"{color}{msg}{reset}"
        return msg
    
    def debug(self, msg):
        self.logger.debug(msg)
    
    def info(self, msg):
        self.logger.info(msg)
    
    def warn(self, msg):
        self.logger.warning(msg)
    
    def warning(self, msg):
        self.logger.warning(msg)
    
    def error(self, msg):
        self.logger.error(msg)
    
    def fatal(self, msg):
        self.logger.critical(msg)


def create_logger(name="rk3576", use_zlog=None, zlog_conf="/etc/zlog.conf", 
                  zlog_category="default", log_file=None, level=logging.INFO):
    """
    åˆ›å»ºæ—¥å¿—å™¨ï¼ˆå·¥å‚å‡½æ•°ï¼‰
    
    Args:
        name: æ—¥å¿—å™¨åç§°
        use_zlog: æ˜¯å¦ä½¿ç”¨ zlogï¼ŒNone=è‡ªåŠ¨æ£€æµ‹
        zlog_conf: zlog é…ç½®æ–‡ä»¶è·¯å¾„
        zlog_category: zlog æ—¥å¿—ç±»åˆ«
        log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆä»… PC æ¨¡å¼ï¼‰
        level: æ—¥å¿—çº§åˆ«
    
    Returns:
        logger å®ä¾‹
    """
    # è‡ªåŠ¨æ£€æµ‹ï¼šæœ‰ libzlog.so å°±ç”¨ zlog
    if use_zlog is None:
        try:
            import ctypes
            ctypes.CDLL("libzlog.so")
            use_zlog = os.path.exists(zlog_conf)
        except OSError:
            use_zlog = False
    
    if use_zlog:
        try:
            return ZLogWrapper(zlog_conf, zlog_category)
        except Exception as e:
            print(f"[WARNING] zlog åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ° logging: {e}")
            return ColoredLogger(name, level, log_file)
    else:
        return ColoredLogger(name, level, log_file)


# å…¨å±€é»˜è®¤ zlog å®ä¾‹
zlog = create_logger("rk3576")


# å¿«æ·å‡½æ•°
def info(msg):
    zlog.info(msg)

def debug(msg):
    zlog.debug(msg)

def warn(msg):
    zlog.warn(msg)

def warning(msg):
    zlog.warning(msg)

def error(msg):
    zlog.error(msg)

def fatal(msg):
    zlog.fatal(msg)
```

---

## common/detector.py

```python
"""
ç»Ÿä¸€æ£€æµ‹å™¨æ¥å£ - æ”¯æŒ ONNX å’Œ RKNN

è‡ªåŠ¨è¯†åˆ«æ¨¡å‹æ ¼å¼ï¼Œæä¾›ç»Ÿä¸€çš„ detect() æ¥å£
"""
import os
import cv2
import numpy as np
from abc import ABC, abstractmethod

from .preprocess import preprocess_with_letterbox, restore_coords
from .postprocess import yolov8_postprocess, get_class_name
from .config import MODEL_INPUT_SIZE, OBJ_THRESH, NMS_THRESH
from .logger import zlog


class BaseDetector(ABC):
    """æ£€æµ‹å™¨æŠ½è±¡åŸºç±»"""
    
    def __init__(self, obj_thresh=None, nms_thresh=None):
        self.obj_thresh = obj_thresh if obj_thresh is not None else OBJ_THRESH
        self.nms_thresh = nms_thresh if nms_thresh is not None else NMS_THRESH
        self.input_size = MODEL_INPUT_SIZE
        self._scale = 1.0
        self._pad = (0, 0)
    
    @abstractmethod
    def _inference(self, img_input):
        """å­ç±»å®ç°ï¼šæ‰§è¡Œæ¨¡å‹æ¨ç†"""
        pass
    
    @abstractmethod
    def release(self):
        """å­ç±»å®ç°ï¼šé‡Šæ”¾èµ„æº"""
        pass
    
    def detect(self, img):
        """
        ç»Ÿä¸€æ£€æµ‹æ¥å£
        
        Args:
            img: BGR å›¾åƒ
        
        Returns:
            boxes: æ£€æµ‹æ¡† [[x1,y1,x2,y2], ...]ï¼ˆåŸå›¾åæ ‡ï¼‰
            classes: ç±»åˆ« ID
            scores: ç½®ä¿¡åº¦
            names: ç±»åˆ«åç§°
        """
        # é¢„å¤„ç†
        img_input, self._scale, self._pad = preprocess_with_letterbox(img, self.input_size)
        
        # æ¨ç†
        outputs = self._inference(img_input)
        
        # åå¤„ç†
        boxes, classes, scores = yolov8_postprocess(
            outputs, self.obj_thresh, self.nms_thresh, self.input_size
        )
        
        # åæ ‡è¿˜åŸ
        if boxes is not None:
            boxes = restore_coords(boxes, self._scale, self._pad)
            names = [get_class_name(int(c)) for c in classes]
            return boxes, classes, scores, names
        
        return None, None, None, None
    
    def __enter__(self):
        return self
    
    def __exit__(self, *args):
        self.release()


class ONNXDetector(BaseDetector):
    """ONNX æ¨¡å‹æ£€æµ‹å™¨ï¼ˆPC ç«¯å¼€å‘ç”¨ï¼‰"""
    
    def __init__(self, model_path, obj_thresh=None, nms_thresh=None):
        super().__init__(obj_thresh, nms_thresh)
        
        import onnxruntime as ort
        self.session = ort.InferenceSession(model_path)
        self.input_name = self.session.get_inputs()[0].name
        self.model_path = model_path
        zlog.info(f"[ONNX] åŠ è½½æ¨¡å‹: {model_path}")
    
    def _inference(self, img_input):
        """ONNX æ¨ç†"""
        # ONNX éœ€è¦ NCHW + float32 + å½’ä¸€åŒ–
        img = img_input.transpose((2, 0, 1))
        img = img.reshape(1, *img.shape).astype(np.float32) / 255.0
        outputs = self.session.run(None, {self.input_name: img})
        return outputs
    
    def release(self):
        """é‡Šæ”¾èµ„æº"""
        self.session = None


class RKNNDetector(BaseDetector):
    """RKNN æ¨¡å‹æ£€æµ‹å™¨ï¼ˆæ¿ç«¯éƒ¨ç½²ç”¨ï¼‰"""
    
    def __init__(self, model_path, obj_thresh=None, nms_thresh=None, core_mask=None):
        super().__init__(obj_thresh, nms_thresh)
        
        # è‡ªåŠ¨è¯†åˆ« PC è¿˜æ˜¯æ¿ç«¯
        try:
            from rknnlite.api import RKNNLite
            self.rknn = RKNNLite()
            self.is_lite = True
            zlog.info(f"[RKNN-Lite] åŠ è½½æ¨¡å‹: {model_path}")
        except ImportError:
            from rknn.api import RKNN
            self.rknn = RKNN()
            self.is_lite = False
            zlog.info(f"[RKNN] åŠ è½½æ¨¡å‹: {model_path}")
        
        ret = self.rknn.load_rknn(model_path)
        if ret != 0:
            raise RuntimeError(f"åŠ è½½æ¨¡å‹å¤±è´¥: {model_path}")
        
        if self.is_lite and core_mask is not None:
            ret = self.rknn.init_runtime(core_mask=core_mask)
        else:
            ret = self.rknn.init_runtime()
        
        if ret != 0:
            raise RuntimeError("åˆå§‹åŒ–è¿è¡Œæ—¶å¤±è´¥")
        
        self.model_path = model_path
    
    def _inference(self, img_input):
        """RKNN æ¨ç†"""
        # RKNN ç›´æ¥ç”¨ uint8 HWC æ ¼å¼
        outputs = self.rknn.inference(inputs=[img_input])
        return outputs
    
    def release(self):
        """é‡Šæ”¾èµ„æº"""
        if self.rknn is not None:
            self.rknn.release()
            self.rknn = None


def create_detector(model_path, obj_thresh=None, nms_thresh=None, core_mask=None):
    """
    å·¥å‚å‡½æ•°ï¼šæ ¹æ®æ¨¡å‹åç¼€è‡ªåŠ¨åˆ›å»ºå¯¹åº”çš„æ£€æµ‹å™¨
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„ï¼ˆ.onnx æˆ– .rknnï¼‰
        obj_thresh: ç½®ä¿¡åº¦é˜ˆå€¼
        nms_thresh: NMS é˜ˆå€¼
        core_mask: NPU æ ¸å¿ƒæ©ç ï¼ˆä»… RKNN æ¿ç«¯æœ‰æ•ˆï¼‰
    
    Returns:
        detector: ONNXDetector æˆ– RKNNDetector å®ä¾‹
    """
    ext = os.path.splitext(model_path)[1].lower()
    
    if ext == '.onnx':
        return ONNXDetector(model_path, obj_thresh, nms_thresh)
    elif ext == '.rknn':
        return RKNNDetector(model_path, obj_thresh, nms_thresh, core_mask)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æ ¼å¼: {ext}ï¼Œæ”¯æŒ .onnx å’Œ .rknn")
```

---

## common/yolo_detector.py

```python
"""
YOLOv8 æ£€æµ‹å™¨ - ç»§æ‰¿ BaseRKNNModel
"""
import cv2
import numpy as np
from .base_model import BaseRKNNModel
from .preprocess import preprocess_with_letterbox, restore_coords
from .postprocess import yolov8_postprocess, get_class_name
from .config import MODEL_INPUT_SIZE, OBJ_THRESH, NMS_THRESH


class YOLOv8Detector(BaseRKNNModel):
    """YOLOv8 ç›®æ ‡æ£€æµ‹å™¨"""
    
    def __init__(self, model_path, core_mask=None, obj_thresh=None, nms_thresh=None):
        """
        åˆå§‹åŒ– YOLOv8 æ£€æµ‹å™¨
        
        Args:
            model_path: RKNN æ¨¡å‹è·¯å¾„
            core_mask: NPU æ ¸å¿ƒæ©ç ï¼ˆä»…æ¿ç«¯æœ‰æ•ˆï¼‰
            obj_thresh: ç½®ä¿¡åº¦é˜ˆå€¼
            nms_thresh: NMS é˜ˆå€¼
        """
        super().__init__(model_path, core_mask)
        self.obj_thresh = obj_thresh if obj_thresh is not None else OBJ_THRESH
        self.nms_thresh = nms_thresh if nms_thresh is not None else NMS_THRESH
        self.input_size = MODEL_INPUT_SIZE
        
        # ç¼“å­˜ letterbox å‚æ•°ï¼Œç”¨äºåæ ‡è¿˜åŸ
        self._scale = 1.0
        self._pad = (0, 0)
    
    def preprocess(self, img):
        """é¢„å¤„ç†ï¼šletterbox + BGRâ†’RGB"""
        img_input, self._scale, self._pad = preprocess_with_letterbox(img, self.input_size)
        return img_input
    
    def postprocess(self, outputs):
        """åå¤„ç†ï¼šè§£ææ£€æµ‹ç»“æœ"""
        boxes, classes, scores = yolov8_postprocess(
            outputs, 
            obj_thresh=self.obj_thresh, 
            nms_thresh=self.nms_thresh,
            img_size=self.input_size
        )
        
        # åæ ‡è¿˜åŸåˆ°åŸå›¾
        if boxes is not None:
            boxes = restore_coords(boxes, self._scale, self._pad)
        
        return boxes, classes, scores
    
    def detect(self, img):
        """
        æ£€æµ‹æ¥å£ï¼ˆå¸¦å¯è§†åŒ–ä¿¡æ¯ï¼‰
        
        Returns:
            boxes: æ£€æµ‹æ¡† [[x1,y1,x2,y2], ...]
            classes: ç±»åˆ« ID
            scores: ç½®ä¿¡åº¦
            names: ç±»åˆ«åç§°åˆ—è¡¨
        """
        boxes, classes, scores = self.infer(img)
        
        if boxes is None:
            return None, None, None, None
        
        names = [get_class_name(int(c)) for c in classes]
        return boxes, classes, scores, names
    
    def draw_results(self, img, boxes, classes, scores, names=None):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ"""
        if boxes is None:
            return img
        
        img_draw = img.copy()
        
        for i, (box, cls, score) in enumerate(zip(boxes, classes, scores)):
            x1, y1, x2, y2 = map(int, box)
            name = names[i] if names else get_class_name(int(cls))
            
            # ä¸åŒç±»åˆ«ç”¨ä¸åŒé¢œè‰²
            color = self._get_color(int(cls))
            
            # ç”»æ¡†
            cv2.rectangle(img_draw, (x1, y1), (x2, y2), color, 2)
            
            # ç”»æ ‡ç­¾èƒŒæ™¯
            label = f"{name}: {score:.2f}"
            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)
            cv2.rectangle(img_draw, (x1, y1 - 20), (x1 + w, y1), color, -1)
            
            # ç”»æ ‡ç­¾æ–‡å­—
            cv2.putText(img_draw, label, (x1, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        return img_draw
    
    def _get_color(self, class_id):
        """æ ¹æ®ç±»åˆ« ID ç”Ÿæˆé¢œè‰²"""
        np.random.seed(class_id)
        return tuple(np.random.randint(0, 255, 3).tolist())
```

---

> **æ€»ä»£ç è¡Œæ•°ï¼š** çº¦ 1200 è¡Œ
> **æ–‡ä»¶æ•°é‡ï¼š** 11 ä¸ª
